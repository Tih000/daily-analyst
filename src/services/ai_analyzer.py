"""GPT-powered analytics engine for journal data."""

from __future__ import annotations

import logging
import statistics
from collections import Counter
from datetime import date, timedelta
from typing import Any, Optional

import openai
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential,
)

from src.config import get_settings
from src.models.journal_entry import (
    BurnoutRisk,
    CorrelationResult,
    DaySummary,
    ForecastResult,
    JournalEntry,
    MonthAnalysis,
    Mood,
    Testik,
    WeakSpot,
)

logger = logging.getLogger(__name__)

SYSTEM_PROMPT = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–Ω–µ–≤–Ω–∏–∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞:
- –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å–Ω–∞/—Ä–∞–±–æ—Ç—ã/–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è/TESTIK
- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è burnout (3+ MINUS TESTIK –ø–æ–¥—Ä—è–¥, <6—á —Å–Ω–∞)
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ–∂–∏–º—É/–∑–∞–¥–∞—á–∞–º
- –ß—ë—Ç–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ü–∏—Ñ—Ä—ã
–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, —Å —ç–º–æ–¥–∑–∏, actionable insights. –ù–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""

# Retry on transient OpenAI errors
_RETRY_EXCEPTIONS = (
    openai.RateLimitError,
    openai.APITimeoutError,
    openai.APIConnectionError,
    openai.InternalServerError,
)


class AIAnalyzer:
    """Analyzes journal entries using GPT and local statistics."""

    def __init__(self) -> None:
        settings = get_settings()
        self._client = openai.AsyncOpenAI(api_key=settings.openai.api_key)
        self._model = settings.openai.model

    # ‚îÄ‚îÄ GPT call helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(min=1, max=15),
        retry=retry_if_exception_type(_RETRY_EXCEPTIONS),
        reraise=True,
    )
    async def _ask_gpt(self, user_prompt: str, max_tokens: int = 1500) -> str:
        """Send a prompt to GPT and return the text response (with retry)."""
        try:
            response = await self._client.chat.completions.create(
                model=self._model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt},
                ],
                max_tokens=max_tokens,
                temperature=0.7,
            )
            return response.choices[0].message.content or ""
        except _RETRY_EXCEPTIONS:
            raise  # let tenacity handle retries
        except Exception as e:
            logger.error("GPT call failed: %s", e)
            return f"‚ö†Ô∏è AI –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}"

    # ‚îÄ‚îÄ Entries to text ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    @staticmethod
    def _entries_to_summary(entries: list[JournalEntry], max_detailed: int = 10) -> str:
        """Convert entries to a compact text summary for GPT context.

        Sends aggregated stats for all entries, plus detailed lines for
        the most recent `max_detailed` entries (with notes) to keep
        token usage manageable.
        """
        if not entries:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."

        sorted_entries = sorted(entries, key=lambda x: x.entry_date)

        # Aggregate stats for full period
        mood_scores = [e.mood.score for e in sorted_entries if e.mood]
        sleep_vals = [e.sleep_hours for e in sorted_entries]
        work_vals = [e.hours_worked for e in sorted_entries]
        prod_vals = [e.productivity_score for e in sorted_entries]
        earnings_vals = [e.earnings_usd for e in sorted_entries]
        testik_counter = Counter(e.testik.value if e.testik else "N/A" for e in sorted_entries)
        workout_count = sum(1 for e in sorted_entries if e.workout)
        uni_count = sum(1 for e in sorted_entries if e.university)

        agg_lines = [
            f"–ü–µ—Ä–∏–æ–¥: {sorted_entries[0].entry_date} ‚Äî {sorted_entries[-1].entry_date} ({len(sorted_entries)} –¥–Ω–µ–π)",
            f"–°—Ä–µ–¥–Ω–∏–µ: mood={statistics.mean(mood_scores):.1f}/5, work={statistics.mean(work_vals):.1f}h, "
            f"sleep={statistics.mean(sleep_vals):.1f}h, productivity={statistics.mean(prod_vals):.1f}"
            if mood_scores else "–°—Ä–µ–¥–Ω–∏–µ: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏",
            f"–ó–∞—Ä–∞–±–æ—Ç–æ–∫: ${sum(earnings_vals):.0f} total, ${statistics.mean(earnings_vals):.1f}/–¥–µ–Ω—å",
            f"TESTIK: {dict(testik_counter)}",
            f"–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏: {workout_count}/{len(sorted_entries)}, –£–Ω–∏–≤–µ—Ä: {uni_count}/{len(sorted_entries)}",
        ]

        # Detailed lines for recent entries (with notes)
        recent = sorted_entries[-max_detailed:]
        detail_lines: list[str] = []
        for e in recent:
            mood_str = e.mood.value if e.mood else "N/A"
            testik_str = e.testik.value if e.testik else "N/A"
            notes_part = ""
            if e.notes and e.notes.strip():
                truncated_note = e.notes.strip()[:120]
                notes_part = f', notes="{truncated_note}"'
            detail_lines.append(
                f"{e.entry_date}: mood={mood_str}, work={e.hours_worked}h, "
                f"tasks={e.tasks_completed}, sleep={e.sleep_hours}h, "
                f"testik={testik_str}, workout={'Y' if e.workout else 'N'}, "
                f"uni={'Y' if e.university else 'N'}, ${e.earnings_usd}, "
                f"score={e.productivity_score}{notes_part}"
            )

        result = "=== –°–≤–æ–¥–∫–∞ ===\n" + "\n".join(agg_lines)
        if len(sorted_entries) > max_detailed:
            result += f"\n\n=== –ü–æ—Å–ª–µ–¥–Ω–∏–µ {max_detailed} –¥–Ω–µ–π (–¥–µ—Ç–∞–ª—å–Ω–æ) ===\n"
        else:
            result += "\n\n=== –î–µ—Ç–∞–ª—å–Ω–æ ===\n"
        result += "\n".join(detail_lines)
        return result

    # ‚îÄ‚îÄ Analytics commands ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def analyze_month(self, entries: list[JournalEntry], month_label: str) -> MonthAnalysis:
        """Full monthly analysis with AI insights."""
        if not entries:
            return MonthAnalysis(
                month=month_label, total_entries=0, avg_mood_score=0,
                avg_hours_worked=0, avg_sleep_hours=0, total_earnings=0,
                total_tasks=0, workout_rate=0, university_rate=0,
                ai_insights="üì≠ –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –∑–∞ —ç—Ç–æ—Ç –º–µ—Å—è—Ü.",
            )

        mood_scores = [e.mood.score for e in entries if e.mood]

        best = max(entries, key=lambda e: e.productivity_score)
        worst = min(entries, key=lambda e: e.productivity_score)

        summary = self._entries_to_summary(entries, max_detailed=15)
        ai_text = await self._ask_gpt(
            f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞ {month_label}:\n{summary}\n\n"
            "–î–∞–π: 1) –ì–ª–∞–≤–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã 2) –ß—Ç–æ —Ö–æ—Ä–æ—à–æ 3) –ß—Ç–æ —É–ª—É—á—à–∏—Ç—å 4) –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–æ–≤–µ—Ç—ã"
        )

        return MonthAnalysis(
            month=month_label,
            total_entries=len(entries),
            avg_mood_score=round(statistics.mean(mood_scores), 2) if mood_scores else 0,
            avg_hours_worked=round(statistics.mean([e.hours_worked for e in entries]), 1),
            avg_sleep_hours=round(statistics.mean([e.sleep_hours for e in entries]), 1),
            total_earnings=sum(e.earnings_usd for e in entries),
            total_tasks=sum(e.tasks_completed for e in entries),
            workout_rate=round(sum(1 for e in entries if e.workout) / len(entries), 2),
            university_rate=round(sum(1 for e in entries if e.university) / len(entries), 2),
            best_day=DaySummary(
                entry_date=best.entry_date,
                productivity_score=best.productivity_score,
                mood=best.mood,
                hours_worked=best.hours_worked,
                tasks_completed=best.tasks_completed,
            ),
            worst_day=DaySummary(
                entry_date=worst.entry_date,
                productivity_score=worst.productivity_score,
                mood=worst.mood,
                hours_worked=worst.hours_worked,
                tasks_completed=worst.tasks_completed,
            ),
            ai_insights=ai_text,
        )

    async def predict_burnout(self, entries: list[JournalEntry]) -> BurnoutRisk:
        """Predict burnout risk for next 5 days based on recent patterns."""
        recent = sorted(entries, key=lambda e: e.entry_date, reverse=True)[:14]
        if len(recent) < 3:
            return BurnoutRisk(
                risk_level="unknown",
                risk_score=0,
                factors=["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –¥–Ω—è)"],
                recommendation="–í–µ–¥–∏ –¥–Ω–µ–≤–Ω–∏–∫ —Ä–µ–≥—É–ª—è—Ä–Ω–æ –¥–ª—è —Ç–æ—á–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤.",
            )

        factors: list[str] = []
        risk = 0.0

        # Factor: consecutive MINUS TESTIK
        last_testiks = [e.testik for e in recent[:7] if e.testik]
        minus_streak = 0
        for t in last_testiks:
            if t in (Testik.MINUS_KATE, Testik.MINUS_SOLO):
                minus_streak += 1
            else:
                break
        if minus_streak >= 3:
            risk += 30
            factors.append(f"üî¥ {minus_streak} MINUS TESTIK –ø–æ–¥—Ä—è–¥")
        elif minus_streak >= 2:
            risk += 15
            factors.append(f"üü° {minus_streak} MINUS TESTIK –ø–æ–¥—Ä—è–¥")

        # Factor: low sleep
        avg_sleep = statistics.mean([e.sleep_hours for e in recent[:7]])
        if avg_sleep < 6:
            risk += 25
            factors.append(f"üò¥ –°—Ä–µ–¥–Ω–∏–π —Å–æ–Ω: {avg_sleep:.1f}—á (<6—á)")
        elif avg_sleep < 7:
            risk += 10
            factors.append(f"üí§ –°—Ä–µ–¥–Ω–∏–π —Å–æ–Ω: {avg_sleep:.1f}—á (<7—á)")

        # Factor: mood trend
        moods = [e.mood.score for e in recent[:7] if e.mood]
        if len(moods) >= 3:
            mood_trend = moods[0] - statistics.mean(moods)
            if mood_trend < -1:
                risk += 20
                factors.append("üìâ –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–∞–¥–∞–µ—Ç")

        # Factor: overwork
        avg_work = statistics.mean([e.hours_worked for e in recent[:7]])
        if avg_work > 10:
            risk += 15
            factors.append(f"‚è∞ –ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞: {avg_work:.1f}—á/–¥–µ–Ω—å")

        # Factor: no workout streak
        no_workout = sum(1 for e in recent[:7] if not e.workout)
        if no_workout >= 5:
            risk += 10
            factors.append(f"üèãÔ∏è {no_workout}/7 –¥–Ω–µ–π –±–µ–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫")

        risk = min(risk, 100)

        if risk >= 70:
            level = "critical"
        elif risk >= 45:
            level = "high"
        elif risk >= 20:
            level = "medium"
        else:
            level = "low"

        summary = self._entries_to_summary(recent[:7])
        ai_rec = await self._ask_gpt(
            f"–†–∏—Å–∫ –≤—ã–≥–æ—Ä–∞–Ω–∏—è: {level} ({risk}%). –§–∞–∫—Ç–æ—Ä—ã: {', '.join(factors)}\n"
            f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π:\n{summary}\n\n"
            "–î–∞–π 3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–æ–≤–µ—Ç–∞ –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ 5 –¥–Ω–µ–π –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –≤—ã–≥–æ—Ä–∞–Ω–∏—è."
        )

        return BurnoutRisk(
            risk_level=level,
            risk_score=risk,
            factors=factors if factors else ["‚úÖ –ù–µ—Ç –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤"],
            recommendation=ai_rec,
        )

    async def best_days(self, entries: list[JournalEntry], top_n: int = 3) -> list[DaySummary]:
        """Return top N most productive days."""
        sorted_entries = sorted(entries, key=lambda e: e.productivity_score, reverse=True)
        return [
            DaySummary(
                entry_date=e.entry_date,
                productivity_score=e.productivity_score,
                mood=e.mood,
                hours_worked=e.hours_worked,
                tasks_completed=e.tasks_completed,
            )
            for e in sorted_entries[:top_n]
        ]

    async def optimal_hours(self, entries: list[JournalEntry]) -> str:
        """Analyze optimal work hours based on productivity patterns."""
        if not entries:
            return "üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        summary = self._entries_to_summary(entries, max_detailed=14)
        return await self._ask_gpt(
            f"–î–∞–Ω–Ω—ã–µ –¥–Ω–µ–≤–Ω–∏–∫–∞:\n{summary}\n\n"
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π: 1) –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤ "
            "2) –°–≤—è–∑—å —á–∞—Å–æ–≤ —Ä–∞–±–æ—Ç—ã –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è "
            "3) –ö–æ–≥–¥–∞ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ "
            "4) –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ —Ä–µ–∂–∏–º—É —Ä–∞–±–æ—Ç—ã"
        )

    async def kate_impact(self, entries: list[JournalEntry]) -> str:
        """Analyze correlation between relationships (TESTIK) and productivity."""
        if not entries:
            return "üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        with_kate: list[JournalEntry] = []
        minus_kate: list[JournalEntry] = []
        for e in entries:
            if e.testik == Testik.PLUS:
                with_kate.append(e)
            elif e.testik == Testik.MINUS_KATE:
                minus_kate.append(e)

        stats_parts: list[str] = []
        if with_kate:
            avg_prod_plus = statistics.mean([e.productivity_score for e in with_kate])
            avg_mood_plus = statistics.mean([e.mood.score for e in with_kate if e.mood])
            stats_parts.append(
                f"PLUS –¥–Ω–∏ ({len(with_kate)}): avg_productivity={avg_prod_plus:.1f}, "
                f"avg_mood={avg_mood_plus:.1f}"
            )
        if minus_kate:
            avg_prod_mk = statistics.mean([e.productivity_score for e in minus_kate])
            avg_mood_mk = statistics.mean([e.mood.score for e in minus_kate if e.mood])
            stats_parts.append(
                f"MINUS_KATE –¥–Ω–∏ ({len(minus_kate)}): avg_productivity={avg_prod_mk:.1f}, "
                f"avg_mood={avg_mood_mk:.1f}"
            )

        summary = self._entries_to_summary(entries[-30:], max_detailed=14)
        return await self._ask_gpt(
            f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–Ω–æ—à–µ–Ω–∏–π:\n{chr(10).join(stats_parts)}\n\n"
            f"–ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π):\n{summary}\n\n"
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–ª–∏—è–Ω–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–π (Kate) –Ω–∞ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, "
            "–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ, —Å–æ–Ω –∏ —Ä–∞–±–æ—Ç—É. –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
        )

    async def testik_patterns(self, entries: list[JournalEntry]) -> str:
        """Analyze TESTIK patterns and their impact on all metrics."""
        if not entries:
            return "üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        by_testik: dict[str, list[JournalEntry]] = {"PLUS": [], "MINUS_KATE": [], "MINUS_SOLO": [], "N/A": []}
        for e in entries:
            key = e.testik.value if e.testik else "N/A"
            by_testik[key].append(e)

        stats_lines: list[str] = []
        for label, group in by_testik.items():
            if not group:
                continue
            avg_prod = statistics.mean([e.productivity_score for e in group])
            avg_sleep = statistics.mean([e.sleep_hours for e in group])
            avg_mood = statistics.mean([e.mood.score for e in group if e.mood]) if any(e.mood for e in group) else 0
            stats_lines.append(
                f"{label} ({len(group)} –¥–Ω–µ–π): productivity={avg_prod:.1f}, "
                f"mood={avg_mood:.1f}, sleep={avg_sleep:.1f}h"
            )

        summary = self._entries_to_summary(entries[-30:], max_detailed=14)
        return await self._ask_gpt(
            f"TESTIK —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n" + "\n".join(stats_lines) + "\n\n"
            f"–î–∞–Ω–Ω—ã–µ:\n{summary}\n\n"
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–∞—Ç—Ç–µ—Ä–Ω—ã TESTIK: 1) –ö–∞–∫ –∫–∞–∂–¥—ã–π —Ç–∏–ø –≤–ª–∏—è–µ—Ç –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏ "
            "2) –ï—Å—Ç—å –ª–∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏ "
            "3) –ß—Ç–æ –¥–µ–ª–∞—Ç—å –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è PLUS –¥–Ω–µ–π"
        )

    async def sleep_optimizer(self, entries: list[JournalEntry]) -> str:
        """Analyze sleep patterns and give optimization advice."""
        if not entries:
            return "üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        sleep_data = [(e.sleep_hours, e.productivity_score, e.mood.score if e.mood else 3) for e in entries]
        avg_sleep = statistics.mean([s[0] for s in sleep_data])
        best_sleep_range = [s for s in sleep_data if s[1] > statistics.mean([x[1] for x in sleep_data])]
        optimal_sleep = statistics.mean([s[0] for s in best_sleep_range]) if best_sleep_range else avg_sleep

        summary = self._entries_to_summary(entries[-30:], max_detailed=14)
        return await self._ask_gpt(
            f"–î–∞–Ω–Ω—ã–µ —Å–Ω–∞: avg={avg_sleep:.1f}—á, optimal={optimal_sleep:.1f}—á\n"
            f"–î–Ω–µ–≤–Ω–∏–∫:\n{summary}\n\n"
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π: 1) –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Å–Ω–∞ –¥–ª—è –º–∞–∫—Å. –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ "
            "2) –í–ª–∏—è–Ω–∏–µ –Ω–µ–¥–æ—Å—ã–ø–∞ –Ω–∞ TESTIK –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ "
            "3) –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏—è —Å–Ω–∞"
        )

    async def money_forecast(self, entries: list[JournalEntry]) -> str:
        """Forecast earnings based on historical patterns."""
        if not entries:
            return "üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞."

        earnings = [(e.entry_date, e.earnings_usd) for e in entries if e.earnings_usd > 0]
        total = sum(e.earnings_usd for e in entries)
        avg_daily = total / len(entries) if entries else 0
        earning_days = len(earnings)

        summary = self._entries_to_summary(entries[-30:], max_detailed=14)
        return await self._ask_gpt(
            f"–ó–∞—Ä–∞–±–æ—Ç–æ–∫: total=${total:.0f}, avg/day=${avg_daily:.1f}, "
            f"earning_days={earning_days}/{len(entries)}\n"
            f"–î–∞–Ω–Ω—ã–µ:\n{summary}\n\n"
            "–î–∞–π: 1) –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –º–µ—Å—è—Ü "
            "2) –°–≤—è–∑—å –∑–∞—Ä–∞–±–æ—Ç–∫–∞ —Å –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é/–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ–º "
            "3) –ö–∞–∫ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ—Ö–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"
        )

    async def weak_spots(self, entries: list[JournalEntry]) -> str:
        """Identify weak spots in productivity patterns."""
        if not entries:
            return "üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        summary = self._entries_to_summary(entries[-30:], max_detailed=14)
        return await self._ask_gpt(
            f"–î–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥:\n{summary}\n\n"
            "–ù–∞–π–¥–∏ –¢–û–ü-5 —Å–ª–∞–±—ã—Ö –º–µ—Å—Ç –≤ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞–π:\n"
            "- –ü—Ä–æ–±–ª–µ–º–∞ + —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å (üî¥/üü°/üü¢)\n"
            "- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã\n"
            "- Actionable —Ä–µ—à–µ–Ω–∏–µ"
        )

    async def tomorrow_mood(self, entries: list[JournalEntry]) -> str:
        """Predict tomorrow's mood based on recent patterns."""
        recent = sorted(entries, key=lambda e: e.entry_date, reverse=True)[:7]
        if len(recent) < 3:
            return "üì≠ –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –∑–∞–ø–∏—Å–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞."

        summary = self._entries_to_summary(recent)
        return await self._ask_gpt(
            f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π:\n{summary}\n\n"
            "–ù–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∂–∏ –∑–∞–≤—Ç—Ä–∞—à–Ω–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ. –î–∞–π:\n"
            "1) –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è (PERFECT/GOOD/NORMAL/BAD/VERY_BAD) —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é\n"
            "2) –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–∞\n"
            "3) –ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å —Å–µ–≥–æ–¥–Ω—è –¥–ª—è –ª—É—á—à–µ–≥–æ –∑–∞–≤—Ç—Ä–∞"
        )
